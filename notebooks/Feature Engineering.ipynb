{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adc54e82",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In this notebook we are going to \"engineer\" some descriptive features which we will use predict to the probability whether a company would default on a loan in the future or not.\n",
    "\n",
    "Let's import some packages we'll use for manipulating and visualising the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10ab988",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotnine import *\n",
    "pd.set_option('mode.chained_assignment',None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9abec6",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "We already created our study sample in the previous notebook. There is a copy of this sample which is publicly available in the GitHub [repo](https://github.com/data-analytics-in-business/gabor-firm-exit-case-study). Therefore we just need to use the `read_csv` method to download and import the data using its URL path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b8b312",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://github.com/data-analytics-in-business/gabor-firm-exit-case-study/raw/main/data/sample_2012.csv\"\n",
    "sample = pd.read_csv(url)\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9438c88d",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "We are not going to be using all the columns in the sample to create features. Let's assume we discussed with the client organisation (the bank) and they suggested developing a *baseline* model which uses data relating to sales, profit & loss, and the industry category of the organisation.\n",
    "\n",
    "We will now inspect each of these *domain concepts* and consider how we might use them to engineer features.\n",
    "\n",
    "**Note**: For the benefit of what is to come, we will ensure our target feature `default` is set to be a *string* type object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0c1b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['default'] = sample['default'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727c87a2",
   "metadata": {},
   "source": [
    "## Sales\n",
    "Let's first investigate the sales data for the companies in our sample. We will use the `ggplot` function from the `plotnine` [package](https://plotnine.readthedocs.io/en/stable/index.html). Don't worry too much about the details of the plotting package, it's just a tool we use here to quickly create some visualisations for the purpose of investigation.\n",
    "\n",
    "Run the code below to create a plot of the `sales` data from the `sample`, using the [`geom_density`](https://plotnine.readthedocs.io/en/stable/generated/plotnine.geoms.geom_density.html) to create a [kernel density estimate](https://en.wikipedia.org/wiki/Kernel_density_estimation) of the sales data.\n",
    "\n",
    "**Note**: We also use our `default` target feature to split and plot the sales data separately for companies we believe would and would not default in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737f7ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ggplot(sample, aes(x='sales', color='default', fill='default'))\n",
    "     + geom_density(alpha=0.1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1bafcd",
   "metadata": {},
   "source": [
    "We see from the plot that distrobution of the sales data has a very [long tail](https://en.wikipedia.org/wiki/Long_tail). When this is the case, we wil often [*transform*](https://en.wikipedia.org/wiki/Data_transformation_(statistics)) the data before we pass it to a machine learning model. One way to do this (for data > 0) is to perform a [logarithm](https://en.wikipedia.org/wiki/Logarithm) (log) transformation.\n",
    "\n",
    "Let's use the `numpy` package to log-transform our sales data and then visualise it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc58db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['log_sales'] = np.log(sample['sales'])\n",
    "(ggplot(sample, aes(x='log_sales', color='default', fill='default'))\n",
    "     + geom_density(alpha=0.1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0462df2",
   "metadata": {},
   "source": [
    "The data looks much more [*normal*](https://en.wikipedia.org/wiki/Normal_distribution) now, and we can even start to see a difference in the distribution of 2012 sales for companies who we believe will default in 2014..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6368fe",
   "metadata": {},
   "source": [
    "## Profit and Loss\n",
    "Let's now visualise the distributions of profit (P&L) and loss data in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3e7c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ggplot(sample, aes(x='profit_loss_year', color='default', fill='default'))\n",
    "     + geom_density(alpha=0.1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa7bac6",
   "metadata": {},
   "source": [
    "The distribution of P&L values also have very long tail(s), but this time they are negative as well as positive. We are going to need to use a slightly more advanced transformation.\n",
    "\n",
    "**Note**: There is a warning above which we can remove by *imputing* the NA values from the `profit_loss_year` column.\n",
    "\n",
    "Run the code below to transform the P&L values, impute the NA values, and visualise the transformed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911e1a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['p+l_scaled'] = np.sign(sample['profit_loss_year'])*(np.log(np.abs(sample['profit_loss_year'])+1))\n",
    "sample['p+l_scaled'] = np.where(sample['p+l_scaled'].isna(), 0, sample['p+l_scaled'])\n",
    "\n",
    "(ggplot(sample, aes(x='p+l_scaled', color='default', fill='default'))\n",
    "     + geom_density(alpha=0.1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c64b04b",
   "metadata": {},
   "source": [
    "The transformed data is not \"normal\" because it is [*bimodal*](https://en.wikipedia.org/wiki/Multimodal_distribution), but it is again much easier to see a difference companies who we believe will and will not default in 2014."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f161073",
   "metadata": {},
   "source": [
    "## Industry type\n",
    "Finally, we investigate the industry types of the companies in our sample. We use the `ind` column and create an additional category `0` for companies that have NA in the `ind` column. We also ensure the final `ind_cat` feature is a *string* so that it is not confused to be numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eeb0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['ind_cat'] = sample['ind']\n",
    "sample['ind_cat'] = np.where(sample['ind_cat'].isna(), 0, sample['ind_cat'])\n",
    "sample['ind_cat'] = sample['ind_cat'].astype(int).astype(str)\n",
    "(ggplot(sample, aes(x='ind_cat',fill='default'))\n",
    " + geom_histogram(binwidth=0.5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3589e544",
   "metadata": {},
   "source": [
    "# Analytics Base Table\n",
    "Now we have engineered descriptive features based suggested domain concepts, we can use them (along with our target feature) to create our final Analytics Base Table (ABT) which we will use for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae39ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ABT = sample[['log_sales','p+l_scaled','ind_cat','default']]\n",
    "sample_ABT.to_csv('../data/sample_2012_ABT.csv', index=False)\n",
    "sample_ABT.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be54158",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "In the code block below:\n",
    "1. Transform the `curr_assets` column through a $log(x+1)$ function to create a new column named `log_assets`\n",
    "2. Find the NA values in `log_assets` and impute them using the value `sample['log_assets'].mean()`\n",
    "3. Visualise the distributions of the `log_assets` data for companies who we believe would and would not deafult\n",
    "\n",
    "Based on the visualisation, do companies who would or would not default have more assests of average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930ec459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (SOLUTION)\n",
    "sample['log_assets'] = np.log(sample['curr_assets']+1)\n",
    "sample['log_assets'] = np.where(sample['log_assets'].isna(), sample['log_assets'].mean(), sample['log_assets'])\n",
    "(ggplot(sample, aes(x='log_assets', color='default', fill='default'))\n",
    "     + geom_density(alpha=0.1)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
